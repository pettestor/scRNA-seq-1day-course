---
title: "Single-Cell RNA-Seq Analysis with Seurat"
author: "PS"
date: "`r Sys.Date()`"
editor:
  markdown:
    wrap: 72
execute:
  warning: false
format:
  html:
    code-copy: true
    toc: true
    page-layout: full
---

# 1. Introduction to Single-Cell RNA Sequencing (scRNA-seq)

A variety of toolkits and analytical frameworks have been developed to
facilitate scRNA-seq data analysis. Among the most widely used are
Seurat, created by Rahul Satija's lab for R, and scanpy, developed by
Fabian Theis's lab for Python. Both provide robust functions and
extensive parameter sets that cover many of the routine analyses
commonly performed on scRNA-seq data. However, it's essential to
recognize that these frameworks may not encompass all possible analyses,
so exploring additional tools can broaden the scope of your data
insights.

In this tutorial, aimed at beginners, we will primarily focus on using
Seurat to analyze scRNA-seq data in R. Throughout this tutorial, we’ll
introduce some additional tools that offer complementary functionalities
beyond Seurat’s capabilities.

This tutorial assumes that preprocessing steps—such as base calling,
mapping, and read counting—have already been completed. For data
generated with the 10x Genomics Chromium Single Cell Gene Expression
Solution, the Cell Ranger pipeline from 10x Genomics is commonly used,
resulting in a count matrix. If your data is from a different technology
(e.g., well-based experiments like Smart-Seq2), the Cell Ranger pipeline
may not be applicable, and an alternative method will be required to
generate the count matrix.

------------------------------------------------------------------------

# 2. Setting Up the Environment

### 2.1 Required Packages

Before starting, ensure you have the following packages installed:

```{r setup, eval=FALSE}
# Install CRAN packages
install.packages(c("Seurat", "dplyr", "ggplot2", "robustbase", "patchwork", "devtools", 
                   "tibble", "viridis"))

# Install Bioconductor packages
if (!requireNamespace("BiocManager", quietly = TRUE)) {
  install.packages("BiocManager")
}
BiocManager::install(c("scater", "harmony", "org.Hs.eg.db", "clusterProfiler", "scRNAseq", "SingleR"))

# Install DoubletFinder from GitHub (since it is not available on CRAN)
devtools::install_github("chris-mcginnis-ucsf/DoubletFinder")

```

### 2.2 Loading Packages

```{r load-libraries, message=FALSE}
# Load libraries
library(Seurat)
library(dplyr)
library(ggplot2)
library(robustbase)
library(scater)
library(DoubletFinder)
library(harmony)
library(patchwork)
library(scRNAseq)
library(SingleR)
library(tibble)
library(viridis)
library(clusterProfiler)
library(org.Hs.eg.db)

sampleColors <-  c("#2A363B", "#019875", "#FF847C", "#E84A5F")

clusterColors <- c(
  "#C0392B", "#96281B", "#B0C4B1", "#D9A441", 
  "#577284", "#4A235A", "#D7BDE2", "#8C6E63",
  "#1F618D", "#FF5733", "#28B463", "#F39C12",
  "#8E44AD", "#16A085", "#E74C3C"
)

```

------------------------------------------------------------------------

# 3. Loading and Preprocessing Data

In this section, we will load a sample dataset and perform quality
control to filter out low-quality and doublet cells.

### 3.1 Loading Data

We will use four midbrain organoid samples sequenced using 10X scRNA-seq
at two timepoints. The data set comes from this
[publication](https://www.nature.com/articles/s41467-021-27464-5).

The goal of this section is to load the raw expression data from 10X
CellRanger and to create a Seurat object. A Seurat object is organized
into multiple slots, including assays (storing expression data),
meta.data (holding cell-level annotations), and reductions (storing
dimensionality reduction results like PCA or UMAP). This design
facilitates seamless preprocessing, visualization, and statistical
analysis workflows within a single framework. The flexibility of the
Seurat object allows for efficient handling of large datasets and
integration of multi-modal data, such as RNA and protein measurements.

```{r load-data}
# Please ensure that your R working directory is set to the location of the data files.
# to check your working directory use the following command
# getwd()
# To move to the directory with the data use the following command
# setwd("path/to/your/data")

# List all directories within the "data/" directory, excluding the top-level "data/" itself.
dirs <- list.dirs("data/organoids/")[-1]

# This step makes sure that the "orig.ident" variable in your Seurat object will be informaticve.
names(dirs) <- c("day60-1","day60-2", "day30-1","day30-2")

# Read in the 10X Genomics data from each specified directory in 'dirs'.
# The 'Read10X' function reads the gene expression count data for each sample into one large matrix
da_diff.data <- Read10X(data.dir = dirs)

# Create a Seurat object with the count data. This is an essential structure in Seurat for
# storing and analyzing single-cell RNA-seq data.
# - 'min.cells = 3' filters out genes not expressed in at least 3 cells.
# - 'min.features = 200' filters out cells that have fewer than 200 detected genes.
da_diff <- CreateSeuratObject(counts = da_diff.data, min.cells = 0, min.features = 0)
```

**Exercise**: In the Cell x Gene expression matrix. What fraction of
cells are == 0?

::: {.panel .panel-collapse}
**Answer:** \~92.5% of the cells have 0 counts for all genes.
:::

### 3.2 Quality Control

A number of factors should be examined before downstream analyses, many
of which we’ll address here:

-   Low library size: When cells are very degraded or absent from the
    library preparation, the number of reads sequenced from that library
    will be very low. It’s important to remove these cells from
    downstream analyses.

-   Low number of expressed genes: A low number of expressed genes
    (which is highly correlated with low library size) may be a result
    of poor-quality cells (e.g. dying, degraded, damaged, etc.),
    followed by high PCR amplification of the remaining RNA. Again,
    these cells should be removed from downstream analyses.

-   High mitochondrial gene content: High concentrations of
    mitochondrial genes is often a result of damaged cells where the
    endogenous RNA escapes or degrades. As mitochondria has its own cell
    membranes, it is often the last DNA/RNA in damaged cells to degrade
    and hence occurs in high quantities during sequencing.

    Fraction of reads originating from the mitochondria will be heavily
    dependent on if you're sequencing cells or nuclei. mtRNA should not
    be present in nuclei preparations and is usually \< 0.1%. For
    scRNA-seq 5-10% can be considered.

-   Batch effect: Large scRNA-seq projects usually need to generate data
    across multiple batches due to logistical constraints. However, the
    processing of different batches is often subject to variation, e.g.,
    changes in operator, differences in reagent quality and
    concentration, the sequencing machine used, etc. This results in
    systematic differences in the observed expression in cells from
    different batches, which we refer to as “batch effects”. Batch
    effects are problematic as they can be major drivers of variation in
    the data, masking the relevant biological differences and
    complicating interpretation of the results. We will look into
    removal of batch effects in section 5.

#### Calculating and inspecting basic QC paramters

```{r quality-control}
# Calculate the percentage of mitochondrial genes
da_diff[["percent.mt"]] <- PercentageFeatureSet(da_diff, pattern = "^MT-")

# Visualize QC metrics
# Number of genes per cell ("nFeature_RNA") and UMIs per cell ("nFeature_RNA") was calculated when we intiated the Seurat object
VlnPlot(da_diff, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"),
        ncol = 3,pt.size = 0)+geom_hline(yintercept = 5, linetype = "dashed") & scale_fill_manual(values=sampleColors)
```

#### Automated identification of cutoffs for filtering

Automated outlier detection is a useful method for identifying
low-quality cells in scRNA-seq datasets. It removes the need for manual
thresholding, which can be subjective and inconsistent, by relying on
statistical measures to flag problematic cells. This approach is
particularly helpful for datasets with complex or variable
distributions, as it adjusts dynamically to the data. It also allows for
multidimensional detection, identifying cells with unusual combinations
of metrics rather than focusing on individual values.

```{r quality-control2}
# Create a matrix of selected statistics from da_diff for analysis
stats <- cbind(da_diff$percent.mt, da_diff$nFeature_RNA, da_diff$nCount_RNA)

# Calculate outlyingness scores for each cell based on the selected statistics
# we will append tthe result to the meta data of the seurat object
# only.outlyingness = TRUE returns only the outlyingness values
da_diff$outlying <- adjOutlyingness(stats, only.outlyingness = TRUE)

# Identify cells that are statistical outliers based on high outlyingness scores
outlier <- isOutlier(da_diff$outlying, type = "higher")

# Summarize the number of outliers identified
summary(outlier)

# Add a column to da_diff indicating if each cell is an outlier
da_diff$is.outlier <- outlier

# Plot nFeature_RNA against nCount_RNA, coloring points by outlier status
# Facet by 'orig.ident' to visualize each sample separately
da_diff@meta.data %>% 
  ggplot(aes(x = nFeature_RNA, y = percent.mt, color = is.outlier)) + 
  geom_point(alpha = 0.6) + 
  scale_color_manual(values = c(sampleColors)) + 
  facet_wrap(~orig.ident) + 
  theme_minimal()

# Violin plot of QC metrics, colored by outlier status
VlnPlot(da_diff, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"),
        split.by = "is.outlier",
        ncol = 3,pt.size = 0) & scale_fill_manual(values=sampleColors)
```

### 3.3 Doublet Removal

Doublets occur when two cells are captured together during single-cell
RNA sequencing, leading to artificial readouts that can distort the
analysis. Detecting and removing doublets is essential to ensure the
integrity of downstream analyses, as they can introduce noise and
misleading biological signals.

In tissues with distinct cell types, such as the brain, cells can be
categorized into well-defined populations based on specific gene
expression profiles. Each cell type has unique markers that facilitate
the identification of doublets, as the combination of two different cell
types will typically produce a distinct expression profile that can be
detected by computational methods. For example, if a doublet is formed
between a neuron and a glial cell, the resulting expression profile may
reveal markers from both cell types, allowing for effective
identification.

In contrast, datasets with continuous maturation feature cells that may
share similar gene expression profiles but exist at different
developmental stages or functional states. For instance, in a dataset
capturing the maturation of immune cells, the transitional states
between precursor cells and fully mature cells can be subtle, making it
difficult to distinguish between single cells and doublets based on gene
expression alone. The absence of distinct markers complicates the
identification process, as the expected combined expression patterns of
doublets may closely resemble those of mature cells.

The table below compares the results of genetic demultiplexing
(considered the ground truth) with the predictions of two doublet
detection algorithms, **DoubletFinder** and **scDblFinder**, for two 10X
samples derived from iDanoids (converted neurons, a mix of three cell
lines). Rows represent the genetic demultiplexing results, while columns
show the classification outcomes from the algorithms.

|         | Both | DoubletFinder | scDblFinder | Neither |
|---------|------|---------------|-------------|---------|
| Doublet | 76   | 1             | 71          | 60      |
| Singlet | 85   | 246           | 260         | 7305    |

**Question**: Based on these results, do you find the predictions from
these algorithms trustworthy?

#### Identifying and Removing Doublets

Nonetheless, we will proceed with running the analysis to familiarize
ourselves with the method using the **DoubletFinder** package in R.
Below is a script demonstrating how to use this method on your Seurat
object to identify and filter out doublets from your dataset. For this
analysis with need to normalize and scale the data and also perform
dimensionality reduction. We will cover these in more detail later.

doubletFinder will add new columns to the meta data. We rename these for
clarity. Finally we plot the predicted doublet status versus number of
detected genes.

```{r}
# Normalize data
da_diff <- NormalizeData(da_diff)
da_diff <- FindVariableFeatures(da_diff)
da_diff <- ScaleData(da_diff)
da_diff <- RunPCA(da_diff, verbose=FALSE)

# Perform doublet detection
da_diff <- doubletFinder(da_diff, 
                                   PCs = 1:20,
                                   pK = 0.1, 
                                   nExp = round(0.05 * ncol(da_diff)), 
                                   reuse.pANN = FALSE)

colnames(da_diff@meta.data) <- colnames(da_diff@meta.data) %>%
  stringr::str_replace("pANN.*", "predicted_doublet_probability") %>%
  stringr::str_replace("DF.classifications.*", "doublet_classification")


da_diff@meta.data %>% ggplot(aes(x=nFeature_RNA, y=nCount_RNA, color=doublet_classification)) + geom_point() + scale_color_manual(values=c("black", "red"))+facet_wrap(~orig.ident+doublet_classification)+theme_bw()

```

**Question**: One more harsh way of removing doublets is to exclude
cells with number of genes detected \> than a manually assigned
threshold. What are pros and cons of that approach?

### 3.4 Final Outlier Filtering

After identifying potential outliers and doublets, we can apply a final
filtering step to exclude cells that are flagged as low quality or
ambiguous. This final filter removes cells based on the previously
calculated outlier status and doublet classification, ensuring that only
high-quality, single-cell data remains for downstream analyses.

```{r}
# Final filtering step to remove outliers and doublets
# Filter out cells that were flagged as outliers or doublets
da_diff.filter<- subset(da_diff, subset = !outlier & doublet_classification != "Doublet")

# Summary of cells retained after filtering
print(paste("Number of cells before final filtering:", ncol(da_diff)))
print(paste("Number of cells retained after final filtering:", ncol(da_diff.filter)))
```

**Question**: What are the risks of having to harsh or to lenient
filtering for removal of bad cells?

------------------------------------------------------------------------

# 4. Normalization and Scaling

### 4.1 Normalization

Normalization, finding variable features, and scaling are essential
preprocessing steps to prepare the data for downstream analysis.
Normalization corrects for differences in sequencing depth between
cells, typically by transforming the raw counts into counts per cell or
counts per million (CPM), followed by log transformation. This step
ensures that expression levels are comparable across cells.

The total number of UMIs observed for a cell are attributable to

1.  cell size (larger cell size =\> more RNA content =\> more expected
    UMIs) (less relevant for snRNA-seq).

2.  Sequencing depth, which will have a large random component and can
    be modelled using a negative binomial distribution.

Let’s look at the expression of a ubiquoulsy expressed gene (GAPDH):

```{r gapdh}
total_umis <- da_diff.filter$nCount_RNA
gene <- "GAPDH"
gene_umi <- GetAssayData(da_diff.filter,layer = "counts")[gene,]

expressionMatrix <- data.frame("total_cell_umi" = total_umis, "gene_umi" = gene_umi)

ggplot(data = expressionMatrix, 
       aes(total_cell_umi, gene_umi)) +
  geom_point(alpha=.5) +
  xlab("Total sequencing depth") +
  ylab(paste0("Gene UMI(", gene,")"))+geom_smooth(method = "lm")+theme_bw()
```

The gene exhibits an almost linear relationship with a cell's sequencing
depth. In this case, the "heterogeneity across cells" in GAPDH
expression levels is primarily due to differences in sequencing depth
rather than biological variability, making it less biologically
interesting.

If all genes exhibited this linear behavior, we could simply account for
sequencing depth by performing a linear regression of observed gene
counts against each cell's total sequencing depth. However, this
approach is problematic because it would negatively impact the
expression of marker genes, such as *NR4A2*, *COL1A1*, and *AQP4*. These
marker genes are only expressed in specific subsets of cells, and
applying linear regression to remove the effect of sequencing depth
would risk dampening their expression, leading to a loss of biologically
relevant information.

Instead of regressing out sequencing depth, an alternative approach is
to use a global scaling factor (e.g., 10,000) to normalize all cells to
a uniform sequencing depth while accounting for the original sequencing
depth of each cell. After scaling the data, it’s common to apply a
log-transformation. The log transformation helps compress the range of
expression values (reducing the influence of highly expressed genes) and
stabilizes the variance across genes. However, since many genes in
scRNA-seq datasets have low or zero expression, you cannot apply the
logarithm directly to zero values (since log⁡(0)\log(0)log(0) is
undefined). To address this, a pseudocount (a small constant,
typically 1) is added to all gene expression values before taking the
logarithm. This ensures that all values are positive and that the
log-transformation can be safely applied. In Seurat, this normalization
can be performed using the `NormalizeData` function:

```{r normalization}
# Normalize data
da_diff.filter <- NormalizeData(da_diff.filter)

gene_umi_normalized <- GetAssayData(da_diff.filter,layer = "data")[gene,]

ggplot(data = data.frame("total_cell_umi" = total_umis,
                         "gene_umi_norm" = gene_umi_normalized), 
       aes(total_cell_umi, gene_umi_norm)) +
  geom_point() +
  theme_bw(base_size = 14) +
  xlab("Total sequencing depth") +
  ylab(paste0("Gene UMI(", gene))+geom_smooth()
  
```

### 4.2 Finding variable features & Scaling

Finding variable features identifies genes with significant expression
variability across cells, which is important because these genes often
capture biologically meaningful patterns, while others contribute more
noise. Variable features are selected based on metrics like variance or
mean-variance relationships, providing a focused subset of genes for
analysis. Scaling centers and scales the expression data, often by
subtracting the mean and dividing by the standard deviation of each gene
across cells. This step standardizes the gene expression values, making
it easier to compare cell-to-cell variation and enhancing the
performance of algorithms used in downstream analyses like
dimensionality reduction and clustering. Together, these steps improve
the accuracy and interpretability of scRNA-seq data.

The **ScaleData** function is used to scale and center expression data.
This process standardizes the data by shifting the distribution of each
gene’s expression across cells to have a mean of zero and a standard
deviation of one. ScaleData adjusts for cell-to-cell variability by
centering and scaling each gene individually. Using ScaleData is
particularly useful for analyses like PCA, which are sensitive to
differences in gene variance. It also has the flexibility to regress out
certain sources of variation, such as mitochondrial gene content, cell
cycle phase, or other unwanted sources of noise.

```{r variable_f}
# Identify highly variable features
da_diff.filter <- FindVariableFeatures(da_diff.filter, nfeatures = 2000)

VariableFeaturePlot(da_diff.filter) %>% 
  LabelPoints(points = head(VariableFeatures(da_diff.filter),n=20), repel = TRUE)

# Scaling data
da_diff.filter <- ScaleData(da_diff.filter)

```

------------------------------------------------------------------------

# 5. Dimensionality Reduction and Clustering

### 5.1 Principal Component Analysis (PCA)

After quality control, filtering and normalization, the next step in
single-cell RNA sequencing analysis is usually to explore the structure
of the data by grouping similar cells and visualizing these groupings in
a reduced-dimensional space. This is achieved through **dimensionality
reduction** and **clustering**.

Dimensionality reduction techniques help to condense complex,
high-dimensional scRNA-seq data into fewer dimensions, making it easier
to identify patterns and relationships among cells. Clustering
algorithms then group cells with similar gene expression profiles,
revealing potential cell types or states present in the dataset.

**Principal Component Analysis (PCA)** is one of the most commonly used
dimensionality reduction methods in scRNA-seq analysis. PCA transforms
the data by identifying principal components, which capture the axes of
maximum variance in the data, thereby highlighting major sources of
variation. Here, we run PCA on the filtered dataset using the most
variable genes to capture the essential features of the data, selecting
50 principal components (PCs) to examine. The ElbowPlot function helps
determine the number of PCs to retain by visualizing the point where
adding more components provides diminishing returns in variance
explained.

```{r pca}
# Run PCA
da_diff.filter <- RunPCA(da_diff.filter, 
                         features = VariableFeatures(object = da_diff.filter),
                        npcs = 50,
                        verbose = FALSE)

# Visualize PCA
ElbowPlot(da_diff.filter, ndims = 50)

```

### 5.2 Clustering and Visualization

Once we have a reduced representation of the data from PCA, we proceed
with clustering to group cells based on their similarity. In this
workflow, we use the `FindNeighbors` function to calculate the local
neighborhood structure of cells based on their PCA coordinates, followed
by `FindClusters` to assign each cell to a cluster. The resolution
parameter is set to 0.5 to control the granularity of clusters, with
higher values yielding more clusters.

In constructing the local neighborhood structure, `FindNeighbors`
employs a **Shared Nearest Neighbor (SNN)** approach to refine the
clustering accuracy. The SNN method goes beyond simple k-nearest
neighbors by assessing the overlap of each cell’s neighborhood with
those of other cells. Cells are considered more similar if they share
multiple nearest neighbors, resulting in a **weighted graph** that
highlights stronger connections between cells with high shared neighbor
counts. This added layer of similarity enhances clustering stability by
prioritizing dense regions of cells that share local neighborhoods,
thereby emphasizing biologically relevant groupings in complex data.

To visualize these clusters, we apply Uniform Manifold Approximation and
Projection (UMAP), which provides a 2D projection of the data,
preserving local and some global structure in the clustering. The UMAP
plot provides an intuitive visual of how cells are grouped, making it
easier to explore potential cell types or states within the dataset.
However, the UMAP should not be overinterpreted. UMAP performs
dimensionality reduction, which inherently simplifies the data. While
this reduction is helpful for visualizing high-dimensional scRNA-seq
datasets, it inevitably loses some information. Rare cell populations or
subtle differences between similar cell states may not be adequately
captured in the UMAP embedding. Unlike principal component analysis
(PCA), where axes represent specific directions of variance, UMAP’s axes
are not directly tied to biologically meaningful dimensions. As a
result, the spatial arrangement of clusters should be interpreted with
caution. For instance, the distance between clusters in UMAP space does
not always reflect the true degree of similarity or dissimilarity
between cell populations. Lastly, UMAP results are influenced by its
parameters, such as the number of neighbors and the minimum distance.
These parameters affect the resolution of the embedding and can alter
the apparent number and shape of clusters.

```{r clustering}
# Find clusters
da_diff.filter <- FindNeighbors(da_diff.filter, dims = 1:20)
da_diff.filter <- FindClusters(da_diff.filter, resolution = 0.1)

# Run UMAP for visualization
da_diff.filter <- RunUMAP(da_diff.filter, dims = 1:20)
DimPlot(da_diff.filter, reduction = "umap", group.by = "seurat_clusters",cols=clusterColors)+
  DimPlot(da_diff.filter, group.by = "orig.ident", reduction = "umap",cols = sampleColors)

```

### 5.3 Integration Using Harmony

Batch correction in scRNA-seq is necessary when technical variation
influences the data, masking biological differences. This is critical if
samples from different conditions or groups were processed in separate
batches, as variations in sequencing runs or reagents can introduce
unwanted noise. Knowing when to apply batch correction depends on the
experimental design, data structure, and the specific downstream
analyses planned. Importantly, batch correction should never replace
proper experimtal design and planning. Running all "treated" samples on
day 1 and then on day 2 run all "control" samples is an example of poor
experimental planing.

The harmony algorithm provides an effective approach to integrating data
from different sources while controlling for these batch effects.
Harmony works by iteratively adjusting the embeddings of cells in a
lower-dimensional space, aligning them based on shared biological
variation while minimizing differences caused by batch effects. This is
achieved through a low-rank approximation of the data, which allows for
the simultaneous consideration of both biological and technical sources
of variation.

To integrate datasets using Harmony, we start by running PCA on each
dataset separately. Once we have the PCA embeddings, we can pass them to
the RunHarmony function, specifying the variable that represents the
batch or dataset. Harmony then re-embeds the cells, producing a new PCA
representation that mitigates batch effects while retaining the
biological structure.

After integrating the datasets with Harmony, we can proceed with
clustering and visualization using the adjusted embeddings. This
integration enhances the robustness of downstream analyses, allowing for
more accurate identification of cell types or states across datasets,
and ensuring that biological signals are not overshadowed by batch
variability.

```{r harmony-integration}
# Integrate using Harmony
da_integrated <- RunHarmony(da_diff.filter, group.by.vars = "orig.ident")

# Proceed with clustering and visualization on the Harmony-adjusted embeddings
da_integrated <- FindNeighbors(da_integrated, dims = 1:30, reduction = "harmony")
da_integrated <- FindClusters(da_integrated, resolution = 0.1)
da_integrated <- RunUMAP(da_integrated, reduction = "harmony",
                         dims = 1:30,reduction.name = "umap_harmony")

# Visualize the integrated data
DimPlot(da_integrated, reduction = "umap_harmony", group.by = "seurat_clusters", cols=clusterColors, label=T) +
DimPlot(da_integrated, group.by = "orig.ident", reduction = "umap_harmony", cols = sampleColors,shuffle = T)
```

------------------------------------------------------------------------

# 6. Saving your processed object

At this stage, it's a good idea to save your Seurat object. This allows
you to pick up your analysis directly from this point in the future,
whether revisiting your project or sharing it with a colleague. To do
this, we'll save the object as an RDS file. The RDS format is a standard
way to store R objects, preserving all the data and metadata associated
with your analysis.

```{r save_rds}
dir.create("processed_data/",showWarnings = F)
saveRDS(da_integrated, "processed_data/da_integrated.rds")
```

To reload the object in the future, you can use the following command:

```{r load_rds}
# Load the saved Seurat object
da_integrated <- readRDS("processed_data/da_integrated.rds")
```

# 7. Annotating Clusters

Clustering cells assigns an identity label to each one, allowing us to
infer that cells with the same label are similar and likely represent
the same cell type or state. Determining the specific cell types or
states corresponding to these clusters can be challenging, and there is
often no definitive answer. However, several approaches can help clarify
this issue:

1.  **Examine the expression of canonical cell type and cell state
    markers** within the clusters. This method relies on established
    knowledge of well-characterized markers in the field.

2.  **Identify signature or marker genes** for each cell cluster (i.e.
    running differential expression analysis between clusters). Once
    these genes are determined, literature searches, enrichment
    analyses, or experimental validations can be conducted to further
    refine annotations.

3.  **Compare the gene expression profiles of the clusters** with
    existing reference datasets using automated methods. This can
    provide additional context for identifying the nature of the
    clusters.

#### 7.1 Canonical Markers


It is important to note that the first method requires prior knowledge
of the system being studied, including a comprehensive list of accepted
markers relevant to the context. For instance, in the context of
differentiating dopamine neurons from stem cells, several suitable
marker genes have been identified, including:

-   MKI67, TOP2A, CENPF: Genes involved in the cell cycle, often used to
    mark proliferating cells.
-   SOX2, HES1, NES: Key genes associated with neurogenesis, marking
    neural stem or progenitor cells.
-   FABP7, SHH, CORIN, FOXA2, LMX1B, OTX2: Markers of floor plate
    progenitors, important for specifying ventral midbrain neurons.
-   TH, EN1, PBX1, STMN2: Genes involved in dopamine (DA) neurogenesis;
    critical for identifying dopamine neuron lineage and development.
-   AQP4, GFAP, EDNRB, GJA1: Markers of astrocytes, essential for
    identifying and studying astrocytic populations.
-   COL1A1, COL1A2, LUM: Genes associated with vascular and
    leptomeningeal cells (VLMCs), playing a role in extracellular matrix
    formation and support.

These genes serve as a starting point for assessing the identity of
midbrain progenitor derivatives in clusters derived from stem cell
differentiation.

You have probably seen multiple ways of showing gene expression in scRNA-seq data 
with the most common being feature plots, dot plots, violin plots and heatmaps.

```{r canonical-markers}

# Canonical markers for dopamine neurons
genes <- c(
  "MKI67","TOP2A","CENPF", # Cell cycle
  "SOX2", "HES1", "NES",         # Neurogenesis
  "FABP7", "SHH", "CORIN", "FOXA2", "LMX1B", "OTX2", # Floor plate progenitors
  "TH", "EN1", "PBX1", "STMN2",           # DA neurogenesis
  "AQP4", "GFAP", "EDNRB",        # Astrocyte
  "COL1A1", "COL1A2", "LUM"   # VLMC
)

# Feature plot for a subset of canonical markers
FeaturePlot(da_integrated,features = c("TOP2A","NES","STMN2","COL1A1"), reduction = "umap_harmony", order =T)

# Violin plot for canonical markers
VlnPlot(da_integrated,features = c("TOP2A","NES","STMN2","COL1A1"), ncol = 2,pt.size = 0)

# Dot plot for canonical markers
DotPlot(da_integrated, features = genes,dot.scale = 8)+
  #Rotate x axis labels
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  # Update colors to something prettier
viridis::scale_color_viridis(direction = -1)

# Heatmap
# heatmap will use the scaled data slot so we need to make sure that all genes we want to plot have been scaled
da_integrated <- ScaleData(da_integrated,features = genes)
DoHeatmap(da_integrated, features = genes)


```
**Question**: What are the pro and cons of the different ways of plotting? 

**Question**: It's not a bad idea to revisit some of the QC parameters that we look at 
in the beginning but with a cluster based view? Can you find any clusters with a suspicous profile?

#### 7.2 Gene modules

Instead of looking at one marker at a time we can also create list(s) of
relevant genes and calculate a module score for each cluster. AddModuleScore is a function in 
the Seurat package used for calculating and adding custom gene module scores to a Seurat object. 
It allows users to evaluate the aggregate expression of predefined sets of genes (modules or signatures) across
cells. This can help identify whether certain biological pathways or processes are more active in different 
cell types or clusters.

In this example we are using Gene Ontology terms to create gene modules
for neurogenesis, cell cycle and stress response. We then calculate a
module score for each cluster and visualize the results.

```{r module-markers}
# Download gene modules from GO related to neurogenesis, cell cycle and stress

gene_modules <- list(
  # Generation of cells within the nervous system
  Neurogenesis=bitr("GO:0071542", fromType="GOALL", toType="SYMBOL", OrgDb='org.Hs.eg.db') %>% pull("SYMBOL"), 
  # Cellular response to hypoxia
  Stress_Response=bitr("GO:0071456", fromType="GOALL", toType="SYMBOL", OrgDb='org.Hs.eg.db') %>% pull("SYMBOL"),
  # Cell cycle
  Cell_Cycle=bitr("GO:0007049", fromType="GOALL", toType="SYMBOL", OrgDb='org.Hs.eg.db') %>% pull("SYMBOL"))

for(i in names(gene_modules)) {
  da_integrated <- AddModuleScore(object = da_integrated, 
                                  features = list(gene_modules[[i]]), 
                                  name = i)
}

# Add module score will add the score in the metadata with the name of the list but append 1 to the name.
# As we have seen before the VlnPlot function can be used to visualise features in the metadata
VlnPlot(
    da_integrated,
    features = paste0(names(gene_modules),"1"),
    pt.size = 0, cols = clusterColors)
```

#### 7.3 Identifying Marker Genes

Marker genes are genes that are differentially expressed in specific
cell populations or clusters and can be used to characterize the
biological functions and identities of these populations. In scRNA-seq
analysis, marker genes are typically identified by comparing the
expression levels between clusters of cells, often using statistical
tests to find genes that are uniquely expressed in particular groups.

Historically, the most common used method has been yhe Wilcoxon test on
single cells which treats each cell as an independent observation,
comparing gene expression distributions between clusters. This method is
sensitive to subtle differences in cell states and does not require
aggregating data, making it straightforward to implement. However, it
assumes cells are independent, which can overlook the biological reality
that cells within the same cluster or sample are correlated. This can
lead to inflated statistical significance due to the large number of
cells.

More recentyl, pseudobulk approaches has gained traction. Pseudobulk
methods aggregate the expression data within each cluster or sample
before performing differential expression analysis. By treating each
sample as a unit, pseudobulk analysis accounts for biological
replication and reduces the impact of technical noise, usually providing
more robust and reproducible results.

Here we will use the Wilcoxon test as implemented in the Seurat funciton
*FindAllMarkers* to identify marker genes for each cluster. We will then
visualize the top 10 marker genes for each cluster using a heatmap.

```{r markers}
# Find markers for each cluster
da_diff.markers <- FindAllMarkers(da_integrated, only.pos = TRUE,
                                  min.pct = 0.25, logfc.threshold = 0.25)


# downsample to 100 cells per cluster
da_integrated.subsampled.metadata <- da_integrated@meta.data %>% rownames_to_column() %>% group_by(seurat_clusters) %>% sample_n(50) 


# top 20 genes per cluster
da_diff.markers.top <- da_diff.markers %>% group_by(cluster) %>% top_n(5, avg_log2FC) %>% arrange(cluster, avg_log2FC) %>% pull(gene)

# Heatmap for canonical markers
da_integrated <- ScaleData(da_integrated, features = da_diff.markers.top)
DoHeatmap(da_integrated, features = da_diff.markers.top, group.by = "seurat_clusters",cells =da_integrated.subsampled.metadata$rowname)

```

#### 7.4.1 Automated annotation using singleR

The third way that we will try out to classify cells is by using
reference-based classification methods, which rely on prior knowledge of
gene expression profiles for known cell types. SingleR is a powerful
tool for this task, which performs reference-based classification of
single-cell data by comparing the gene expression profiles of the cells
in your dataset to a reference dataset of annotated cell types.

In this analysis, we use the LaMannoBrainData reference dataset, which
contains gene expression data for human embryonic brain cell types, to
classify cells from a different dataset, the data comes from [this
paper](https://pubmed.ncbi.nlm.nih.gov/27716510/). The classification
results are then added to the Seurat object as metadata, allowing us to
visualize and analyze the cell type predictions.

```{r singler, cache = TRUE}
# Prepare la manno data set
la_manno_ref <- LaMannoBrainData(which = "human-embryo")
logcounts(la_manno_ref) <- log2(counts(la_manno_ref)+1)

# Run SingleR to classify cells
singleR_results <- SingleR(
  test = as.SingleCellExperiment(da_integrated),
  ref = la_manno_ref,  
  labels = la_manno_ref$Cell_type
)

# Add SingleR predictions as metadata to Seurat object
da_integrated$SingleR_label <- singleR_results$labels

# Visualize SingleR predictions
DimPlot(da_integrated, group.by = "SingleR_label", reduction = "umap_harmony",label = T)
```

To further refine the cell type classification, we can filter out cell
types with low representation in the dataset. This step helps focus the
analysis on the most prevalent and well-characterized cell types,
improving the interpretability of the results.

```{r singler_filter, cache = TRUE}

# Calculate percentage of each cell type
cell_type_counts <- table(da_integrated$SingleR_label)

# Update metadata to include only cell types above threshold
da_integrated$Filtered_SingleR_label <- ifelse(
  da_integrated$SingleR_label %in% names(cell_type_counts[cell_type_counts > 200]),
  da_integrated$SingleR_label,
  NA  # or use "Other"
)

# UMAP plot with filtered cell types
DimPlot(da_integrated, group.by = "Filtered_SingleR_label",reduction = "umap_harmony",  label = TRUE, na.value = "grey") + 
    ggtitle("Filtered Cell Type Classification ( > 200 cells)") 

```

#### 7.4.2 Automated annotation using Seurats labeltransfer

Seurat's Label Transfer function is another method used to transfer cell
type annotations or other labels from a reference dataset onto a query
dataset in single-cell RNA-seq analysis. Label Transfer works by first
aligning the datasets through the integration of shared biological
features, then identifying anchor points (common structures or cell
states) between the reference and query. Using these anchors, Seurat
calculates a prediction score for each label in the reference dataset
and transfers the highest-scoring labels to the query cells. This method
maintains biological consistency between datasets while accounting for
batch effects or differences in sequencing protocols, making it a
powerful tool for harmonizing annotations across single-cell studies.

```{r label_t}

la_manno.seu <- CreateSeuratObject(counts = counts(la_manno_ref), project = "LaMannoBrainData",
                                   meta.data = data.frame(colData(la_manno_ref)))

la_manno.seu <- la_manno.seu[,la_manno.seu$Cell_type!="Unk"]
la_manno.seu <- la_manno.seu %>% NormalizeData() %>% FindVariableFeatures(nfeatures = 4000) %>% ScaleData() %>% RunPCA(npcs = 30, verbose = F)


# Find anchors between the reference and query datasets
anchors <- FindTransferAnchors(reference = la_manno.seu, query = da_integrated, dims = 1:30)

# Transfer labels from the reference to the query dataset
predictions <- TransferData(anchorset = anchors, refdata =la_manno.seu$Cell_type)

# Add transferred labels to the query dataset
da_integrated <- AddMetaData(da_integrated, metadata = predictions)


# Lets remove cells only found in low numbers
cell_type_counts_label_transfer <- table(predictions$predicted.id)

# Update metadata to include only cell types above threshold
da_integrated$filtered_label_transfer <- ifelse(
  da_integrated$predicted.id %in% names(cell_type_counts_label_transfer[cell_type_counts_label_transfer > 200]),
  da_integrated$predicted.id,
  NA  # or use "Other"
)


# Visualize the transferred labels
DimPlot(da_integrated, group.by = "filtered_label_transfer", reduction = "umap_harmony", label = T)
```

The prediction.score.max in Seurat's label transfer reflects the
confidence of a predicted label for a query cell, ranging from 0 (low
confidence) to 1 (high confidence). Higher scores indicate a strong
match between the query cell and a reference cell type, while lower
scores suggest poor matches, potential novel cell types, or technical
noise. You can use thresholds to filter low-confidence cells or analyze
them further for biological insights. Proper interpretation depends on
the quality of the reference dataset and the context of your analysis.

```{r label_t2}

# 
FeaturePlot(da_integrated, features = c("prediction.score.max"),order=T,min.cutoff = "q9",reduction = "umap_harmony")
```

------------------------------------------------------------------------


# 8. Extras


### 8.1. Interacting with the seurat object
The Seurat object is a central data structure that stores single-cell RNA-seq data and associated metadata in an organized manner. Understanding how to access and manipulate the data within this object is crucial for performing custom analyses and visualizations.

In this section, we explore how to access cell names, gene names, and expression values, as well as metadata and dimensional reduction results.

```{r 8_1}
# Storing all cell names in a vector
cell_names <- colnames(da_integrated)
# Number of cells
length(cell_names)

# Storing all gene names in a vector
gene_names <- rownames(da_integrated)

# Accessing raw expression values of a specific gene across all cells
# Raw data from the counts layer (sparse matrix) for the TH gene
gene_expression_raw <- GetAssayData(da_integrated, assay = "RNA", slot = "counts")["TH", ]

# Accessing normalized expression values
gene_expression_normalized <- GetAssayData(da_integrated, assay = "RNA", slot = "data")["TH", ]

# Accessing metadata for cells
cell_metadata <- da_integrated@meta.data

# Retrieving a specific metadata column
nFeature_RNA <- da_integrated$`nFeature_RNA`

# Modifying metadata (adding a new custom metadata column)
da_integrated$sample_group <- ifelse(da_integrated$orig.ident == "day30-1" | da_integrated$orig.ident == "day30-2", "day30", "day60")

# Accessing dimension reduction embeddings (e.g., UMAP)
umap_coordinates <- Embeddings(da_integrated, reduction = "umap")
head(umap_coordinates)

# Subsetting the object to include only cells from a specific cluster
cluster_subset <- subset(da_integrated, idents = "1")

# Subsetting based on metadata values
subset_high_genes <- subset(da_integrated, subset = nFeature_RNA > 2000)

```

### 8.2 Pathway Analysis with clusterProfiler

In this section, we perform pathway enrichment analysis using marker
genes identified in **Section 7.3**. The **clusterProfiler** package
allows us to investigate biological pathways associated with clusters or
conditions of interest.

```{r pw1}
# Filter significant markers for a specific cluster (e.g., Cluster 1)
cluster5_markers <- da_diff.markers %>% 
  filter(cluster == "5" & p_val_adj < 0.05) %>%  # Adjust for your cluster and significance threshold
  pull(gene)

# Convert gene symbols to Entrez IDs
entrez_ids <- bitr(cluster5_markers, fromType = "SYMBOL", 
                   toType = "ENTREZID", 
                   OrgDb = org.Hs.eg.db)

# GO enrichment analysis
go_results <- enrichGO(gene = entrez_ids$ENTREZID,
                       OrgDb = org.Hs.eg.db, 
                       keyType = "ENTREZID", 
                       ont = "BP",         # Biological Process ontology
                       pAdjustMethod = "BH", 
                       pvalueCutoff = 0.05)

# View summary of enriched GO terms
# Dot plot
dotplot(go_results, showCategory = 10) + 
  ggtitle("Top 10 GO Terms for Biological Processes")

# KEGG pathway enrichment analysis
kegg_results <- enrichKEGG(gene = entrez_ids$ENTREZID,
                           organism = 'hsa',       # Use 'mmu' for mouse
                           pvalueCutoff = 0.05)

# Visualize KEGG results
dotplot(kegg_results, showCategory = 10) +
  ggtitle("Top 10 Enriched KEGG Pathways")



```

### 8.3 Identifying number of clusters

The resolution parameter in Seurat’s FindClusters function controls the
granularity of clustering, with higher resolutions producing more
fine-grained clusters. However, determining the optimal resolution can
be challenging, especially when biological relevance is not immediately
apparent.

The clustree package provides a powerful visualization tool to assess
how clusters evolve across different resolutions. By creating a
tree-like structure, clustree highlights how clusters merge or split as
resolution changes, aiding in the identification of biologically
meaningful patterns. This section demonstrates how to generate
clustering solutions at multiple resolutions and visualize them using
clustree.

```{r clustree}
# Load required libraries
#install.packages(c("clustree"))
library(clustree)

# Perform clustering for a range of resolutions
resolutions <- seq(0.1, 1, by = 0.2)         # Define a range of resolutions
da_diff <- FindNeighbors(da_integrated, dims = 1:20, reduction = "harmony") # Identify cell neighbors

for (res in resolutions) {
  da_integrated <- FindClusters(
    da_integrated,
    resolution = res,                          # Specify the current resolution
    verbose = FALSE                            # Suppress output
  )
}

# clustree visualization
clustree(da_integrated@meta.data, prefix = "RNA_snn_res.") +
  theme_minimal() +
  ggtitle("Clustering Resolution Tree") +
  xlab("Resolution") +
  ylab("Clusters")

```

In addition to clustree, other methods like silhouette analysis can help
assess the quality and biological relevance of clustering results.
Silhouette analysis provides a metric that quantifies how well a cell
fits within its assigned cluster compared to neighboring clusters. A
high silhouette width indicates well-separated clusters, while a low or
negative silhouette width suggests overlapping or poorly defined
clusters.

Silhouette anaylis can be used both to asses the stability of a given
clustering results but also to find the optimal number of clusters by
optimizing the overall silhouette score.

Here we will use silhouette analysis to look at the stability of the
clustering results at a given resolution.

```{r silhouette}
# Load required libraries
library(cluster)

# Extract the cluster assignments and the PCA coordinates
clusters <- da_integrated$RNA_snn_res.0.1              # Cluster labels, here with resolution 0.1
coords <- Embeddings(da_integrated, reduction = "harmony")[, 1:20] # PCA coordinates (first 10 dimensions)

# Compute the silhouette width
sil <- silhouette(as.numeric(clusters)-1, dist(coords))

# Convert silhouette object to a data frame for visualization
sil_df <- as.data.frame(sil[, 1:3]) # Columns: cell ID, cluster, silhouette width
colnames(sil_df) <- c("Cluster", "Neighboring_Cluster", "Silhouette_Width")
sil_df$Cluster <- as.factor(sil_df$Cluster)

# Plot silhouette widths for each cluster
ggplot(sil_df, aes(x = Cluster, y = Silhouette_Width, fill = Cluster)) +
  geom_boxplot() +
  labs(
    title = "Silhouette Analysis of Clusters",
    x = "Cluster",
    y = "Silhouette Width"
  ) +
  theme_minimal()+scale_fill_manual(values = clusterColors)
```

### 8.4 Cell Cycle Analysis

Cell cycle phase can be a significant source of variation in scRNA-seq
data, influencing gene expression patterns and clustering results. To
account for this, we can use the **CellCycleScoring** function in Seurat
to assign a cell cycle phase to each cell based on the expression of
cell cycle-related genes. This information can then be used to adjust
for cell cycle effects in downstream analyses.

For each cell, CellCycleScoring calculates the S.Score and G2M.Score by
averaging the expression of predefined S-phase and G2/M-phase marker
genes, respectively. These scores quantify the activity of
phase-specific genes, providing a basis for classification. A cell is
assigned to the S-phase if the S.Score exceeds the G2M.Score, to the
G2/M-phase if the G2M.Score is higher, and to the G1-phase if both
scores are low, indicating quiescence or non-dividing status. This
classification captures cell cycle progression with a straightforward
scoring comparison.

```{r cca}

# Load predefined cell cycle gene sets from Seurat
s.genes <- Seurat::cc.genes.updated.2019$s.genes  # Genes associated with S-phase
g2m.genes <- Seurat::cc.genes.updated.2019$g2m.genes  # Genes associated with G2/M-phase

# Perform cell cycle scoring
da_integrated <- CellCycleScoring(
  da_integrated,                           # Seurat object to classify
  s.features = s.genes,              # Gene set for S-phase
  g2m.features = g2m.genes,          # Gene set for G2/M-phase
  set.ident = TRUE                   # Update cell identities based on the predicted phase
)

# View the resulting cell cycle scores
head(da_integrated@meta.data[, c("S.Score", "G2M.Score", "Phase")])

```

### 9.5 Species classification

In some scRNA-seq experiments, cells may be derived from multiple
species, such as human-mouse xenografts. We will start by creating the
seurat object.

```{r create_multi_species_seu}
# Read the 10X Genomics data
graft.data <- Read10X(data.dir = "data/grafts/G1_YZ013_SD_no12/") 
# Remove the "grch38_" prefix from gene names for easier readability
rownames(graft.data)<-gsub("premRNAGRCH38-","",rownames(graft.data)) 
# Create a Seurat object with the count data
graft <- CreateSeuratObject(counts = graft.data, 
                            min.cells = 3, min.features = 200)
```

Next step is to use the fraction of reads mapping to rat and human
genome to identify cell types.

```{r create_multi_species_seu2}
# Calculate the total counts for Rat-specific features
# Extract features matching the Rat pattern ("premRNARnor6--") from the "counts" layer and sum them row-wise

ratGenes <- grep("^premRNARnor6--", rownames(graft),value = TRUE)
graft$RatCounts <- colSums(GetAssayData(graft, assay = "RNA", slot = "counts")[ratGenes, ])

# Calculate the total counts for Human-specific features
# Extract features NOT matching the Rat pattern ("premRNARnor6--") from the "counts" layer and sum them row-wise
humanGenes <- grep("^premRNARnor6--",
                          rownames(graft),
                          invert = TRUE,
                          value = TRUE)

graft$HumanCounts <- colSums(GetAssayData(graft, assay = "RNA", slot = "counts")[humanGenes, ])
```

**Question**: If we splitted the rat and human counts correctly they should add up to the variable
`nCount_RNA` what was automatically added to the meta data when we created the Seurat object. Do they?


```{r create_multi_species_seu3}
# Compute the percentage of counts attributed to Rat-specific features
graft$PercentRat <- PercentageFeatureSet(graft, features = ratGenes)

# Compute the percentage of counts attributed to Human-specific features
# Use the set of features that do not match the Rat-specific pattern
graft$PercentHuman <- PercentageFeatureSet(graft,
                                           features = humanGenes)

# Classify cells into species based on the percentage of Rat-specific features
graft$Species <- case_when(
  graft$PercentRat < 20 ~ "Human",   # Less than 20% Rat features indicates a Human cell
  graft$PercentRat > 80 ~ "Rat",     # More than 80% Rat features indicates a Rat cell
  TRUE ~ "Unknown/Doublet"                   # Anything in between is classified as "Unknown"
)

# Generate a scatter plot showing Rat counts vs. Human counts
# Group the points by the classified species
FeatureScatter(graft, feature1 = "RatCounts", feature2 = "HumanCounts", group.by = "Species") +
  ggtitle("Species Classification") + # Add a title to the plot
  xlab("Rat Counts") +                # Label the x-axis
  ylab("Human Counts")                # Label the y-axis

# Create a subset of the Seurat object containing only cells classified as "Human"
graft.human <- subset(graft, subset = Species == "Human")

# And you can start with QC and so on... 
# Note that this was a sample with very few human cells only used for illustrative purposes...

```
